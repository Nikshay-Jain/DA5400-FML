{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98241480",
   "metadata": {},
   "source": [
    "# Nikshay Jain | MM21B044\n",
    "## Assign 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec53ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import os, csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623675a3",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca5009",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0462f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 60000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"mnist\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cba24104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image', 'label'],\n",
      "    num_rows: 60000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset['train']\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3366f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = {i: [] for i in range(10)}\n",
    "for idx, data in enumerate(train_data):\n",
    "    label = data['label']\n",
    "    if len(subset[label]) < 100:\n",
    "        subset[label].append((data['image'], label))\n",
    "    if all(len(subset[i]) == 100 for i in range(10)):\n",
    "        break\n",
    "\n",
    "final_subset = []\n",
    "for key in subset:\n",
    "    final_subset.extend(subset[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e86f0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(final_subset)\n",
    "\n",
    "os.makedirs(\"mnist_dataset\", exist_ok=True)\n",
    "images = \"mnist_dataset\\images\"\n",
    "labels = \"mnist_dataset\\labels.csv\"\n",
    "os.makedirs(images, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbb834f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(labels, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Image_Path\", \"Label\"])\n",
    "    for i, (image, label) in enumerate(final_subset):\n",
    "        image_path = os.path.join(images, f\"image_{i}.png\")\n",
    "        image.save(image_path)\n",
    "        writer.writerow([image_path, label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe7cf5",
   "metadata": {},
   "source": [
    "## Part (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2be3f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to centre the data baout mean\n",
    "def centre_data(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    data_new = data - mean\n",
    "    return data_new, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e395d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigen_decomposition(cov_matrix):\n",
    "    eigenvals, eigenvecs = np.linalg.eigh(cov_matrix)\n",
    "    sorted_indices = np.argsort(eigenvals)[::-1]    # Sort eigenvalues and eigenvectors in descending order\n",
    "    eigenvals = eigenvals[sorted_indices]\n",
    "    eigenvecs = eigenvecs[:, sorted_indices]\n",
    "    return eigenvals, eigenvecs\n",
    "\n",
    "def project_data(data, eigenvectors, n_components):\n",
    "    \"\"\"Project data onto the top n_components eigenvectors.\"\"\"\n",
    "    return np.dot(data, eigenvectors[:, :n_components])\n",
    "\n",
    "def visualize_principal_components(eigenvectors, img_shape, n_components):\n",
    "    \"\"\"Visualize the principal components as images.\"\"\"\n",
    "    for i in range(n_components):\n",
    "        plt.subplot(1, n_components, i + 1)\n",
    "        plt.imshow(eigenvectors[:, i].reshape(img_shape), cmap='gray')\n",
    "        plt.title(f\"PC {i + 1}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def calculate_variance_explained(eigenvalues):\n",
    "    \"\"\"Calculate the proportion of variance explained by each principal component.\"\"\"\n",
    "    total_variance = np.sum(eigenvalues)\n",
    "    variance_explained = eigenvalues / total_variance\n",
    "    return variance_explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9521ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccdbfa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (_, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69e4b4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd31cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten images to 2D (n_samples, n_features)\n",
    "n_samples, img_height, img_width = X_train.shape\n",
    "X = X_train[:1000].reshape(1000, img_height * img_width)\n",
    "\n",
    "# PCA Implementation\n",
    "\n",
    "X_std, mean = centre_data(X)\n",
    "cov_matrix = np.cov(X_std.T)       # to calc the cov matrix for the centred dataset\n",
    "eigenval, eigenvec = eigen_decomposition(cov_matrix)\n",
    "\n",
    "# Number of components to visualize\n",
    "n_components = 5\n",
    "visualize_principal_components(eigenvectors, (img_height, img_width), n_components)\n",
    "\n",
    "# Variance explained by each principal component\n",
    "variance_explained = calculate_variance_explained(eigenvalues)\n",
    "for i in range(n_components):\n",
    "    print(f\"PC {i + 1}: Variance Explained = {variance_explained[i] * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
